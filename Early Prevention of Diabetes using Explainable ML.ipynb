{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9fac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install Jinja2\n",
    "# %pip install imbalanced-learn\n",
    "# %pip install --upgrade pypalettes\n",
    "# %pip install shap\n",
    "# %pip install lime\n",
    "%pip show ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,StratifiedKFold,GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score,\n",
    "                             recall_score, f1_score, confusion_matrix,\n",
    "                             ConfusionMatrixDisplay, classification_report, roc_curve,make_scorer,roc_auc_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from lime import lime_text\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from imblearn.pipeline import Pipeline\n",
    "from scipy.stats import randint, uniform\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import display\n",
    "\n",
    "import shap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c857f6",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f076e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\Master\\Completed Unit\\ICT_606_Machine Learning_TSA24\\Assignment 1_27 Sep 24\\diabetes_data_upload.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa07c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b9dee",
   "metadata": {},
   "source": [
    "# 2.1.1 EDA\n",
    "# A .Imbalanced Distribution of Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.subplot(121)\n",
    "df[\"class\"].value_counts().plot.pie(autopct = \"%1.0f%%\",colors = sns.color_palette(\"prism\",7),startangle = 60,labels=[\"Positive\",\"Negative\"],\n",
    "wedgeprops={\"linewidth\":2,\"edgecolor\":\"k\"},explode=[.1,0],shadow =True)\n",
    "plt.title(\"Distribution of Target  Variable\")\n",
    "\n",
    "plt.subplot(122)\n",
    "ax = df[\"class\"].value_counts().plot(kind=\"barh\")\n",
    "\n",
    "for i,j in enumerate(df[\"class\"].value_counts().values):\n",
    "    ax.text(.7,i,j,weight = \"bold\",fontsize=20)\n",
    "\n",
    "plt.title(\"Count of Target Variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c218607d",
   "metadata": {},
   "source": [
    "# B .Gender Distribution on Positive Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.countplot(df, x=\"Gender\",hue='class')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "\n",
    "plot_criteria= ['Gender', 'class']\n",
    "\n",
    "cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "(round(pd.crosstab(df[plot_criteria[0]], df[plot_criteria[1]], normalize='columns') * 100,2)).style.background_gradient(cmap = cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c86b702",
   "metadata": {},
   "source": [
    "# C.Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f929b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map 'positive' to 1 and 'negative' to 0\n",
    "df['class'] = df['class'].apply(lambda x: 0 if x=='Negative' else 1)\n",
    "df['class'].head()\n",
    "\n",
    "# drop class column\n",
    "X = df.drop(['class'], axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Storing Features\n",
    "objectList = X.select_dtypes(include = \"object\").columns\n",
    "print(objectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for object to numeric conversion\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feature in objectList:\n",
    "    X[feature] = X[feature].astype('category').cat.codes\n",
    "\n",
    "print (X.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea002faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrame to store Chi-Square statistics or p-values\n",
    "chi2_stats = pd.DataFrame(index=objectList, columns=['Chi2 Stat', 'P-value'])\n",
    "\n",
    "# Perform Chi-Square test for each categorical feature\n",
    "for feature in X.columns:\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(X[feature], y)\n",
    "\n",
    "    # Perform Chi-Square test\n",
    "    chi2_stat, p_value, dof, ex = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Store results\n",
    "    chi2_stats.loc[feature, 'Chi2 Stat'] = chi2_stat\n",
    "    chi2_stats.loc[feature, 'P-value'] = p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ad73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_plot=X.corrwith(y)\n",
    "print(corr_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05748bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame(corr_plot, columns=['Correlation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27fda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, fmt='.2f')\n",
    "plt.title('Correlation of Features with Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad10a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is numeric\n",
    "chi2_stats['Chi2 Stat'] = pd.to_numeric(chi2_stats['Chi2 Stat'], errors='coerce')\n",
    "chi2_stats['P-value'] = pd.to_numeric(chi2_stats['P-value'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(chi2_stats[['P-value']], annot=True, cmap='coolwarm', fmt='.2f', vmin=0, vmax=1)\n",
    "plt.title('P-Values Heatmap')\n",
    "plt.xlabel('P-Value')\n",
    "plt.ylabel('Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b737c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_stats = df.groupby('class')['Age'].describe()\n",
    "age_stats['IQR'] = age_stats['75%'] - age_stats['25%']\n",
    "\n",
    "# Create a boxplot\n",
    "plt.figure(figsize=(5, 5))\n",
    "boxplot = sns.boxplot(x='class', y='Age', data=df, palette='Set2')\n",
    "\n",
    "# Overlay IQR with error bars\n",
    "for i, class_label in enumerate(age_stats.index):\n",
    "    q1 = df[df['class'] == class_label]['Age'].quantile(0.25)\n",
    "    q3 = df[df['class'] == class_label]['Age'].quantile(0.75)\n",
    "    print(q1)\n",
    "    print(q3)\n",
    "    iqr = q3 - q1\n",
    "    plt.errorbar(x=i, y=age_stats.loc[class_label, 'mean'],\n",
    "                 yerr=iqr / 2, fmt='o', color='red', capsize=5)\n",
    "\n",
    "\n",
    "plt.title('Age Distribution by Class with IQR Highlights')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with KDE overlay\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(data=df, x='Age', hue='class', kde=True, palette='Set2', bins=15)\n",
    "plt.title('Histogram and KDE of Age by Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b30b1a",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_1 = df.drop(['class'], axis=1)\n",
    "y_1 = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding for object to numeric conversion\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feature in objectList:\n",
    "    X_1[feature] = X_1[feature].astype('category').cat.codes\n",
    "\n",
    "print (X_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc64ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "x_1scaled = StandardScaler().fit_transform(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc26bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce from 16 to 5 features with PCA\n",
    "pca = PCA(n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b880d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform data\n",
    "pca_features = pca.fit_transform(x_1scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of explained_variance\n",
    "explained_variance = pca.explained_variance_\n",
    "explained_variance_ratio = pca.explained_variance_ratio_ * 100\n",
    "\n",
    "# Sort explained variance and ratios in descending order\n",
    "sorted_indices = np.argsort(explained_variance_ratio)[::-1]  # Indices for sorting in descending order\n",
    "sorted_explained_variance = explained_variance_ratio[sorted_indices]\n",
    "sorted_cumulative_variance = np.cumsum(sorted_explained_variance)\n",
    "\n",
    "# Create a scree plot\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.bar(range(1, len(sorted_explained_variance) + 1), sorted_explained_variance, alpha=0.6, color='b', label='Individual Explained Variance')\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(1, len(sorted_explained_variance) + 1), sorted_cumulative_variance, color='red', marker='o', label='Cumulative Explained Variance')\n",
    "\n",
    "# Annotate each cumulative point with its percentage\n",
    "for i, cum_var in enumerate(sorted_cumulative_variance):\n",
    "    plt.annotate(f'{cum_var:.1f}%',\n",
    "                 xy=(i + 1, cum_var),\n",
    "                 xytext=(i + 1, cum_var + 3),  # Adjust vertical position as needed\n",
    "                 ha='center',\n",
    "                 fontsize=9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Mark the elbow point (adjust this index based on your analysis)\n",
    "elbow_index = 2 # Adjust based on where you visually determine the elbow is\n",
    "plt.axvline(x=elbow_index, color='green', linestyle='--', label='Elbow Point')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('PCA Feature')\n",
    "plt.ylabel('Explained Variance (%)')\n",
    "plt.title('Scree Plot (Explained Variance by Principal Components)')\n",
    "plt.xticks(range(1, len(explained_variance) + 1))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming feature_names is defined from the columns of X_1\n",
    "feature_names = X_1.columns\n",
    "\n",
    "def create_pca_biplot(X, y, feature_names, n_components=2, scale=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Generates a PCA biplot visualizing the first two principal components\n",
    "    and the contribution of the original features, with enhanced visual clarity.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame or np.ndarray): The feature data.\n",
    "        y (pd.Series or np.ndarray): The target variable for coloring data points.\n",
    "        feature_names (list): List of feature names corresponding to the columns of X.\n",
    "        n_components (int, optional): Number of principal components to compute. Defaults to 2.\n",
    "        scale (bool, optional): Whether to scale the data before applying PCA. Defaults to True.\n",
    "        **kwargs: Additional keyword arguments passed to plt.scatter.\n",
    "    \"\"\"\n",
    "    if scale:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X_scaled = X\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_features = pca.fit_transform(X_scaled)\n",
    "    explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    plt.figure(figsize=(10, 10))  # Increased figure size for better readability\n",
    "    scatter = plt.scatter(pca_features[:, 0], pca_features[:, 1],\n",
    "                            c=y, cmap=plt.cm.RdBu,  # More informative colormap\n",
    "                            alpha=0.7, edgecolor='k', s=80, **kwargs) # Increased marker size and black edges\n",
    "\n",
    "    # Add arrows for feature vectors with improved aesthetics and scaling\n",
    "    feature_vectors = pca.components_.T\n",
    "    scale_factor = max(np.abs(pca_features[:, :2]).flatten()) * 0.7  # Adjust scale for better fit\n",
    "\n",
    "    for i, varname in enumerate(feature_names):\n",
    "        x = feature_vectors[i, 0] * scale_factor\n",
    "        y = feature_vectors[i, 1] * scale_factor\n",
    "        plt.arrow(0, 0, x, y, color='forestgreen', alpha=0.8, linewidth=1.2, head_width=0.05 * scale_factor, head_length=0.1 * scale_factor)\n",
    "        plt.text(x * 1.1, y * 1.1, varname, fontsize=12, color='dimgray', ha='center', va='center',\n",
    "                 bbox=dict(facecolor='white', edgecolor='lightgray', boxstyle='round,pad=0.2'))\n",
    "\n",
    "    # Add informative axis labels and title\n",
    "    plt.xlabel(f'Principal Component 1 ({explained_variance_ratio[0]*100:.1f}%)', fontsize=14)\n",
    "    plt.ylabel(f'Principal Component 2 ({explained_variance_ratio[1]*100:.1f}%)', fontsize=14)\n",
    "    plt.title('PCA Biplot Visualizing Data and Feature Contributions', fontsize=16)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.axhline(y=0, color='k', linewidth=0.5)\n",
    "    plt.axvline(x=0, color='k', linewidth=0.5)\n",
    "\n",
    "    # Add a legend if a colormap is used for the target variable\n",
    "    if 'c' in kwargs or (isinstance(y, (np.ndarray, list)) and len(np.unique(y)) > 1):\n",
    "        legend = plt.legend(*scatter.legend_elements(), title=\"Target Class\")\n",
    "        plt.gca().add_artist(legend)\n",
    "\n",
    "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the improved biplot function\n",
    "create_pca_biplot(X_1, y_1, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689537b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y,test_size=0.2,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a35a6",
   "metadata": {},
   "source": [
    "# 2.1.2 RF Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5361781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForest Classifier\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0396784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac40ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with mapped numerical values using map\n",
    "mapping = {'Positive': 1, 'Negative': 0}\n",
    "df_1['class_num'] = df_1['class'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (exclude the target variable 'class_num')\n",
    "feature_columns = X.columns[X.columns != 'class_num']\n",
    "X = df_1[feature_columns]  # Features for training\n",
    "y = df_1['class_num']      #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb66615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "importances = forest.feature_importances_\n",
    "# Feature labels\n",
    "feat_labels = feature_columns\n",
    "# Sort the feature importances in descending order and get indices\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature importances:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{f + 1:2d}) {feat_labels[indices[f]]:<30} {importances[indices[f]]:.6f}\")\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]),importances[indices],align='center')\n",
    "plt.xticks(range(X_train.shape[1]),\n",
    "feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f40b5",
   "metadata": {},
   "source": [
    "# 2.2 Predicitve Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5abbcf4",
   "metadata": {},
   "source": [
    "# Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb28ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE()\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "counter = Counter(y_train_sm)\n",
    "print('After',counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17fb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = list()\n",
    "resample = list()\n",
    "precision = list()\n",
    "recall = list()\n",
    "F1score = list()\n",
    "AUCROC = list()\n",
    "Sensitivity =list()\n",
    "Specificity = list()\n",
    "\n",
    "def test_eval(clf_model, X_test, y_test, algo=None, sampling=None):\n",
    "\n",
    "    # Test set prediction\n",
    "    y_prob=clf_model.predict_proba(X_test)\n",
    "    y_pred=clf_model.predict(X_test)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_val = precision_score(y_test, y_pred)\n",
    "    recall_val = recall_score(y_test, y_pred)\n",
    "    f1score_val = f1_score(y_test, y_pred)\n",
    "    aucroc_val = roc_auc_score(y_test, y_prob[:,1])\n",
    "    sensitivity_val = recall_val\n",
    "    specificity_val = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    # Print metrics\n",
    "    print('Confusion Matrix')\n",
    "    print('='*60)\n",
    "    print(confusion_matrix(y_test,y_pred),\"\\n\")\n",
    "    print('Classification Report')\n",
    "    print('='*60)\n",
    "    print(classification_report(y_test,y_pred),\"\\n\")\n",
    "    print('AUC-ROC')\n",
    "    print('='*60)\n",
    "    print(roc_auc_score(y_test, y_prob[:,1]))\n",
    "    print('='*60)\n",
    "    print('Sensitivity (Recall)')\n",
    "    print('=' * 60)\n",
    "    print(sensitivity_val)\n",
    "    print('=' * 60)\n",
    "    print('Specificity')\n",
    "    print('=' * 60)\n",
    "    print(specificity_val)\n",
    "\n",
    "\n",
    "    # Append metrics to lists\n",
    "    model.append(algo)\n",
    "    precision.append(precision_score(y_test,y_pred))\n",
    "    recall.append(recall_score(y_test,y_pred))\n",
    "    F1score.append(f1_score(y_test,y_pred))\n",
    "    AUCROC.append(roc_auc_score(y_test, y_prob[:,1]))\n",
    "    resample.append(sampling)\n",
    "    Sensitivity.append(sensitivity_val)\n",
    "    Specificity.append(specificity_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa53cf",
   "metadata": {},
   "source": [
    "# Model 1 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [2,10,30,50,100]\n",
    "# Maximum number of depth in each tree:\n",
    "max_depth = [i for i in range(5,16,2)]\n",
    "# Minimum number of samples to consider to split a node:\n",
    "min_samples_split = [2, 5, 10, 15, 20, 50, 100]\n",
    "# Minimum number of samples to consider at each leaf node:\n",
    "min_samples_leaf = [1, 2, 5]\n",
    "# Including both Gini impurity and Entropy\n",
    "criteria = ['gini', 'entropy']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "\n",
    "clf_r = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "rf_params = {\n",
    "    'n_estimators': estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'criterion': criteria  # Add criterion to the hyperparameter grid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eede1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting the RF model\n",
    "clf_RF = RandomizedSearchCV(clf_r, rf_params, cv=cv, scoring='accuracy', n_jobs=-1, n_iter=10, verbose=2)\n",
    "clf_RF.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2673dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_SMOTE= clf_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF Evaluating the Model (After SMOTE):\n",
    "test_eval(clf_RF, X_test, y_test, 'Random Forest', 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc026f",
   "metadata": {},
   "source": [
    "# Model 2 : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83859c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "Scaler_X = StandardScaler()\n",
    "X_train_lr = Scaler_X.fit_transform(X_train)\n",
    "X_test_lr = Scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "log_model=LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    'C': np.logspace(-10, 1, 15),  # Regularization strength\n",
    "    'class_weight': ['balanced'],  # Use balanced class weights\n",
    "    'penalty': ['l1', 'l2'],  # Penalty types\n",
    "    'solver': ['liblinear', 'lbfgs']  # Include solvers that support the penalties\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "# Create grid search using 5-fold cross validation\n",
    "clf_LR = GridSearchCV(log_model, params, cv=cv, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LR model\n",
    "clf_LR.fit(X_train_sm, y_train_sm)\n",
    "LR_SMOTE=clf_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR Evaluating the Model (After SMOTE):\n",
    "test_eval(clf_LR, X_test, y_test, 'Logistic Regression', 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e088bd",
   "metadata": {},
   "source": [
    "# Model 3 : SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f39348",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler().fit(X_train)\n",
    "X_train_SVM = sc.transform(X_train)\n",
    "X_test_SVM = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7631265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVMSMOTE with the current k value\n",
    "svm_smote = SVMSMOTE(k_neighbors=5, random_state=42)\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('svmsmote', svm_smote),\n",
    "    ('svc', svm_model)\n",
    "])\n",
    "# Resample the SVC model\n",
    "X_train_SVM, y_train_SVM = svm_smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Set up StratifiedKFold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "# Set up RandomizedSearchCV to find the best hyperparameters\n",
    "param_grid = {\n",
    "    'svc__C': [1, 10, 100, 1000],\n",
    "    'svc__gamma': [1, 0.1, 0.001, 0.0001],\n",
    "    'svc__kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up RandomizedSearchCV to find the best hyperparameters\n",
    "clf_svm = RandomizedSearchCV(pipeline, param_distributions=param_grid,\n",
    "                                    n_iter=10, cv=cv, scoring='accuracy',\n",
    "                                    n_jobs=-1, verbose=2, random_state=42)\n",
    "\n",
    "clf_svm.fit(X_train_SVM, y_train_SVM)\n",
    "SVM_SMOTE=clf_svm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dcd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(clf_svm, X_test, y_test, 'SVC', 'smote')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8114e65",
   "metadata": {},
   "source": [
    "# ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa475cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 : RF\n",
    "y_pre_prob_1 = RF_SMOTE.predict_proba(X_test)[:, 1]\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y_test, y_pre_prob_1)\n",
    "auc1 = roc_auc_score(y_test, y_pre_prob_1)\n",
    "\n",
    "# Model 2 : LR\n",
    "\n",
    "y_pre_prob_2=LR_SMOTE.predict_proba(X_test)[:, 1]\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y_test, y_pre_prob_2)\n",
    "auc2 = roc_auc_score(y_test, y_pre_prob_2)\n",
    "\n",
    "# Model 3 : SVM\n",
    "\n",
    "y_pre_prob_3=SVM_SMOTE.predict_proba(X_test)[:, 1]\n",
    "fpr3, tpr3, thresholds3 = roc_curve(y_test, y_pre_prob_3)\n",
    "auc3 = roc_auc_score(y_test, y_pre_prob_3)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], [0,1],'k--')\n",
    "plt.plot(fpr1, tpr1, label=\"RF (AUC = %0.4f)\" % auc1)\n",
    "plt.plot(fpr2, tpr2, label=\"LR (AUC = %0.4f)\" % auc2)\n",
    "plt.plot(fpr3, tpr3, label=\"SVM (AUC = %0.4f)\" % auc3)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7581f4b",
   "metadata": {},
   "source": [
    "# 3.1 XAI - SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190401bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffddc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier\n",
    "rf_class = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KernelExplainer\n",
    "explainer = shap.KernelExplainer(rf_class.predict, X_train)\n",
    "\n",
    "# Explain the prediction using the KernelExplainer\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ee26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the summary plot\n",
    "shap.summary_plot(shap_values, X_test, show=False, feature_names=X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
